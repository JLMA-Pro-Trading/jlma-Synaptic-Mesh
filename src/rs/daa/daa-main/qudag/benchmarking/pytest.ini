[pytest]
# Pytest configuration for QuDAG benchmarking tests
minversion = 7.0
testpaths = tests
python_files = test_*.py *_test.py
python_classes = Test*
python_functions = test_*

# Test discovery patterns
addopts = 
    -v
    --strict-markers
    --tb=short
    --cov=benchmarking
    --cov-report=html:reports/coverage
    --cov-report=term-missing
    --benchmark-group-by=group
    --benchmark-sort=name
    --benchmark-save=benchmarks
    --benchmark-save-data
    --benchmark-autosave
    --benchmark-min-rounds=5
    --benchmark-warmup=on
    --benchmark-disable-gc
    --benchmark-histogram=reports/histograms

# Test markers
markers =
    unit: Unit tests for individual components
    integration: Integration tests with QuDAG
    performance: Performance validation tests
    slow: Tests that take longer than 1 second
    benchmark: Performance benchmark tests
    mock: Tests using mocked QuDAG components
    critical: Critical tests that must pass
    smoke: Quick smoke tests for CI/CD
    regression: Regression tests
    memory: Memory usage tests
    concurrent: Concurrency tests
    security: Security-related tests

# Test environment
env = 
    QUDAG_TEST_MODE=true
    RUST_LOG=debug
    BENCHMARK_DATA_DIR=./benchmark_data

# Coverage settings
[coverage:run]
source = benchmarking
omit = 
    */tests/*
    */test_*
    */__pycache__/*
    */venv/*

[coverage:report]
exclude_lines =
    pragma: no cover
    def __repr__
    raise AssertionError
    raise NotImplementedError
    if __name__ == .__main__.:
    if TYPE_CHECKING:
    @abstract

# Logging
log_cli = true
log_cli_level = INFO
log_cli_format = %(asctime)s [%(levelname)8s] %(message)s
log_cli_date_format = %Y-%m-%d %H:%M:%S

# Timeout settings
timeout = 300
timeout_method = thread

# Parallel execution
workers = auto